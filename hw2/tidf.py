# -*- coding: utf-8 -*-
"""tidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JD8hBpMLh3agJQPx3dxFKfR-0G09BQZO
"""

import re
import math

def textProcessing(f):
    with open(f, 'r') as file:
        for i in file.readlines():
            with open(i.strip("\n"), 'r') as innerfile:
                filename = i
                txt = innerfile.read()
                txt = re.sub(r'http\S+', '', txt)
                txt = re.sub(r'[^\w\s]', '', txt)
                txt = re.sub(r'\s+', ' ', txt)
                txt = txt.lower()
                txt = re.sub(r'\b(ourselves|hers|between|yourself|but|again|there|about|once|during|out|very|having|with|they|own|an|be|some|for|do|its|yours|such|into|of|most|itself|other|off|is|s|am|or|who|as|from|him|each|the|themselves|until|below|are|we|these|your|his|through|don|nor|me|were|her|more|himself|this|down|should|our|their|while|above|both|up|to|ours|had|she|all|no|when|at|any|before|them|same|and|been|have|in|will|on|does|yourselves|then|that|because|what|over|why|so|can|did|not|now|under|he|you|herself|has|just|where|too|only|myself|which|those|i|after|few|whom|t|being|if|theirs|my|against|a|by|doing|it|how|further|was|here|than)\b', '', txt)
                #with open("stopwords.txt",'r') as stopfile:
                 #   stopwords = stopfile.read().split()
                #x  = "|".join(stopwords)
                hold = txt.split()
                for i, s in enumerate(hold):
                    x = s
                    x = re.sub(r'(ing|med|ly)$', '', x)
                    hold[i] = x
                txt = ' '.join(hold)
                #txt = txt.lower()
                #write into file
                with open("prepoc_" + filename.strip("\n"), 'w') as outfile:
                    outfile.write(txt)
                print(txt + "\n")

def postProcessing(f):
    #tokenize data from all files

    with open(f, 'r') as file:
        IDFdict= {}
        ncounter = 0
        finaldict = {}
        tmpdict = {}
        tmp2dict = {}
        finale = {}
        hold = []
        hold2 = []
        for i in file.readlines():
            with open("prepoc_" + i.strip("\n"), 'r') as innerfile:
                filename = "prepoc_" + i.strip("\n")
                hold = innerfile.read().split()
                
                #count frequency of terms in hold
                freq = {}
                for i in hold:
                    if i in freq:
                        freq[i] += 1
                    else:
                        freq[i] = 1
                tmp2dict["prepoc_" + filename.strip("\n")] = hold
                #sort by frequency
                for i in freq:
                    freq[i] = freq[i]/len(hold)
                
                freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)
                tmpdict["prepoc_" + filename.strip("\n")] = dict(freq)
                ncounter = ncounter + 1

    #print(tmpdict)
    #print(tmp2dict)
    #calculate idf
    for i in tmpdict:
        for j in tmpdict[i]:
            if j in IDFdict:
                IDFdict[j] += 1
            else:
                IDFdict[j] = 1
    print(ncounter)
    for i in IDFdict:
        IDFdict[i] = math.log(ncounter/IDFdict[i]) + 1
    #print(IDFdict)
    #calculate tf-idf
    for i in tmpdict:
        for j in tmpdict[i]:
            tmpdict[i][j] = round(tmpdict[i][j] * IDFdict[j],2)
    #sort tmpdict by tf-idf
    for i in tmpdict:
        tmpdict[i] = sorted(tmpdict[i].items(), key=lambda x:(-x[1],x[0]))
    #write tmpdict into tfidf_ + line from prepoc_ + test documents
    #=print(tmpdict)
    for i in tmpdict:
        with open("tfidf_" + i.strip("prepoc_"), 'w') as outfile:
            #write top 5 ti-df values in list form, if similar ti-df values are found, then it is sorted alphabetically
            outfile.write(str(tmpdict[i][:5]))           

textProcessing("tfidf_docs.txt")
postProcessing("tfidf_docs.txt")